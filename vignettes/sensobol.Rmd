---
title: "sensobol: an R package to compute variance-based sensitivity indices"
author: "Arnald Puy"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{sensobol}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
preamble: >
  \usepackage{amsmath}
  \usepackage{framed}
  \usepackage{amsmath}
  \usepackage{amssymb}
  \usepackage{float}
  \floatplacement{figure}{H}
  \usepackage{bm}
  \usepackage{makecell}
  \usepackage{booktabs}
  \usepackage{tikz}
  \usetikzlibrary{matrix,decorations.pathreplacing, calc, positioning,fit}
bibliography: REFERENCES.bib
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Usage
In this section we illustrate the functionality of ``sensobol`` through three different examples. Let us first load the required libraries:

```{r setup}
library("sensobol")
library("data.table")
library("ggplot2")
```

\begingroup
\renewcommand{\arraystretch}{1.9}
\begin{table}[!ht]
\centering
\begin{tabular}{llll}
\toprule
\code{first} & \code{total} & \code{matrices} & Nº model runs \\
\midrule
\makecell{\code{"saltelli"} \\ \code{"jansen"}} & \makecell{\code{"jansen"}\\ \code{"sobol"} \\ \code{"homma"} \\ \code{"janon"} \\ \code{"glen"}} & \code{c("A", "B", "AB")} & $N(k + 2)$ \\
\midrule
\code{"sobol"} & \code{"saltelli"} & \code{c("A", "B", "BA")} & $N(k + 2)$ \\
\midrule
\code{"azzini"} & \makecell{\code{"jansen"} \\ \code{"sobol"} \\ \code{"homma"} \\ \code{"janon"} \\ \code{"glen"}\\ \code{"azzini"} \\ \code{"saltelli"}} & \code{c("A", "B", "AB", "BA")} & $2N(k + 1)$ \\
\midrule
\makecell{\code{"saltelli"} \\ \code{"jansen"}\\ \code{"sobol"} \\ \code{"azzini"}} & \code{"azzini"} & \code{c("A", "B", "AB", "BA")} & $2N(k + 1)$ \\
\bottomrule
\end{tabular}
\caption{\label{tab:combinations} Available combinations of first and total-order estimators.}
\end{table}
\endgroup

## Example 1: The Sobol' G function
In sensitivity analysis, the accuracy of sensitivity estimators is usually checked against test functions for which the variance and the sensitivity indices can be expressed analytically. `sensobol` includes five of these test functions: @Ishigami1990's, @Sobol1998's (known as G function), @Bratley1992b's, @Bratley1988a's and @Oakley2004's, as well as @Becker2020's metafunction (Table \ref{tab:test_functions}).

In this first example we illustrate the functionality of `sensobol` with a sensitivity analysis of the Sobol' G function, one of the most used benchmark functions in the sensitivity analysis literature [@LoPiano2020, @Puy2020, @Saltelli2010a]. It is a Type A function, characterized by few important factors and minor interactions [@Kucherenko2011]. In its current implementation, the Sobol' G is an eight-dimension function with $S_1>S_2>S_3>S_4$ and $(S_5,...,S_8)\approx0$ (Table \ref{tab:test_functions}, Nº 4). 

We first define the settings of the uncertainty and sensitivity analysis: we set the sample size $N$ of the base sample matrix and the number of uncertain parameters $k$, and create a vector with the parameters' name. Since we will bootstrap the indices to get confidence intervals, we also set the number of bootstrap replicas $R$ and define the bootstrap confidence interval method, which in this case will be the normal method. Finally, we set the confidence intervals at 0.95:

```{r settings_sobolg, cache=TRUE}
N <- 2 ^ 10
k <- 8
params <- paste("x_", 1:k, sep = "")
R <- 10^3
type <- "norm"
conf <- 0.95
```

The next step is to create the sample matrix. In this specific case we will use an $\mathbf{A}$, $\mathbf{B}$, $\mathbf{A}_B^{(i)}$ design and Sobol' Quasi-Random numbers to compute first and total-order indices. These are default settings in `sobol_matrices()`. In our call to the function we only need to define the sample size and the parameters:

```{r matrix_sobolg, cache=TRUE, dependson="settings_sobolg"}
mat <- sobol_matrices(N = N, params = params)
```

Once the sample matrix is defined we can run our model. Note that in `mat` each column is a model input and each row a sample point, so the model has to be coded as to run rowwise. This is already the case of the Sobol' G function included in `sensobol`:

```{r model_sobolg, cache=TRUE, dependson="matrix_sobolg"}
y <- sobol_Fun(mat)
```

The package also allows the user to swiftly visualize the model output uncertainty by plotting an histogram of the model output obtained from the $\mathbf{A}$ matrix:

```{r unc_sobolg, cache=TRUE, dependson="model_sobolg", fig.cap="Empirical distribution of the Sobol' G model output.", message = FALSE, fig.width=5}
plot_uncertainty(Y = y, N = N) 
```

Before computing Sobol' indices, it is recommended to explore how the model output maps onto the model input space. `sensobol` includes two functions to that aim, `plot_scatter()` and `plot_multiscatter()`. The first displays the model output $y$ against $x_i$ while showing $E_{x_i} \left [ V_{\mathbf{x}_{\sim i}}(y | x_i) \right]$ (i.e. as in Figures 1--2), and allows the user to identify patterns denoting sensitivity [@Pianosi2016].

```{r scatter_sobolg, cache=TRUE, dependson=c("model_sobolg", "matrix_sobolg", "settings_sobolg"), fig.height=7, fig.width=5, fig.cap="Scatterplot of model inputs against the model output for the Sobol' G function."}
plot_scatter(data = mat, N = N, Y = y, params = params)
```

The facetted scatter plots evidence that $x_1$ and $x_3$ have more *shape* than the rest and thus have a higher influence on $y$ than $(x_4,...,x_8)$. However, scatter plots do not always permit to detect which parameters have a joint effect on the model output. To gain a first insight on these second-order interactions, the function `plot_multiscatter()` plots $x_i$ against $x_j$ and maps the resulting coordinate to its respective model output value. Interactions are then visible by the emergence of colored patterns.

By default, `plot_multiscatter()` plots all possible combinations of $x_i$ and $x_j$, which equal $\frac{k!}{2!(k-2)!}$. In high-dimensional models with several inputs this might lead to overplotting. To avoid this drawback, the user can subset the parameters she wishes to focus on following the results obtained with `plot_scatter()`: if $x_i$ does not show *shape* in the scatterplots of $x_i$ against $y$, then it may be excluded from `plot_multiscatter()`.

Below we plot all possible combinations of pairs of inputs between $x_1,...,x_4$, which are influential according to Figure 6:

```{r multiscatter_sobolg, cache=TRUE, dependson=c("model_sobolg", "matrix_sobolg", "settings_sobolg"), fig.height=5, fig.width=5, fig.cap="Scatterplot matrix of pairs of model inputs for the Sobol' G function."}
plot_multiscatter(data = mat, N = N, Y = y, 
                  params = paste("x_", 1:4, sep = ""))
```

The results suggest that $x_1$ might interact with $x_2$ given the colored pattern of the $(x_1, x_2)$ facet: the highest values of the model output are concentrated in the corners of the ($x_1,x_2$) input space and thus result from combinations of high/low $x_1$ values with high/low $x_2$ values. In case the analyst is interested in assessing the exact weight that such interaction has in the model output uncertainty, the computation of second-order indices would be required.

The last step is he computation of sobol' indices. In this specific case, we set `boot = TRUE` to bootstrap the Sobol' indices and get confidence intervals:

```{r indices_sobolg, cache=TRUE, dependson="model_sobolg"}
ind <- sobol_indices(Y = y, N = N, params = params, boot = TRUE, 
                     R = R, type = type, conf = conf)
```

Let's have a look at the output of `sobol_indices()`: to improve the visualization, we set the number of digits in each numerical column to 3:

```{r print_sobolg, cache=TRUE, dependson="indices_sobolg"}
cols <- colnames(ind)[1:5]
ind[, (cols):= round(.SD, 3), .SDcols = (cols)]
print(ind)
```
 
The output when `boot = TRUE` is a `data.table` with the bootstrap statistics in the five leftmost columns (the observed statistic, the bias, the standard error and the low and high confidence intervals), and two extra columns linking each statistic to a sensitivity index (`sensitivity`) and a parameter (`parameters`). If `boot = FALSE`, `sobol_indices()` computes a point estimate of the indices and the output includes only the columns `original`, `sensitivity` and `parameters`. 

The results indicate that $x_1$ is responsible for 72\% of the uncertainty in $y$, followed by $x_2$, which conveys 18\% of the uncertainty. $x_3$ and $x_4$ have a very minor first-order effect, while the rest are non-influential. Note that the observed statistics suggest the presence of non-additivities: $T_1$ and $T_2$ (0.799 and 0.24) are respectively higher than $S_1$ and $S_2$ (0.72 and 0.18). As we have seen in Figure 7, $x_1$ and $x_2$ have a non-additive effect in $y$.

We can also compute the Sobol' indices of a dummy parameter, i.e. a parameter that has no influence on the model output, to estimate the numerical approximation error. This will be used later on to identify parameters whose contribution to the output variance is less than the approximation error, and therefore can not be considered influential. Like `sobol_indices()`, the function `sobol_dummy()` allows to obtain point estimates (the default) or bootstrap estimates. In this example we use the latter option:

```{r dummy_sobolg, cache=TRUE, dependson="indices_sobolg"}
ind.dummy <- sobol_dummy(Y = y, N = N, params = params, boot = TRUE, R = R)
```

The last stage is to plot the Sobol' indices and their confidence intervals, as well as the Sobol' indices of a dummy parameter, with the function `plot_sobol()`:

```{r plot_indices_sobolg, cache=TRUE, dependson="indices_sobolg", fig.height=5, fig.width=5, fig.cap="Sobol' indices of the Sobol' G function."}
plot_sobol(data = ind, dummy = ind.dummy)
```

Note that the error bars of $S_1$ and $S_2$ overlap with those of $T_1$ and $T_2$ respectively. In the case of the Sobol' G function we know that $T_1>S_1$ and $T_2>S_2$ because the analytic variance is known, but for models where this is not the case such overlap might hamper the identification of non-additivities. Under these circumstances, narrower confidence intervals can be obtained by increasing the sample size $N$ and rerunning the analysis from the creation of the sample matrix onwards.

The horizontal, blue / red dashed lines respectively mark the upper limit of the $T_i$ and $S_i$ indices of the dummy parameter. This helps in identifying which parameters do condition the model output given the sample size constraints of the analysis: only those parameters whose lower confidence intervals are not below the $S_i$ and $T_i$ indices of the dummy parameter can be considered truly influential, in this case $x_1$ and $x_2$. Note that although $T_3\ne0$, the $T_i$ index of the dummy parameter is higher than $T_3$ and therefore $T_3$ can not be distinguished from the approximation error.

It is also worth stating that the presence of non-additivities can also be probed with

```{r sum_si_sobolg, cache=TRUE, dependson="indices_sobolg"}
ind[sensitivity == "Si", sum(original)]
```

with $(\sum_{i=1}^{k}S_i) < 1$ indicating a non-additive model.

## Bibliography
